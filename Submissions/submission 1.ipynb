{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "xp0X3WMuWEYZ",
        "WbHXnQ2WWlHO",
        "ZhMRsvQvZh6v",
        "Wmgf_oYl6hr0",
        "WE7gk3Wj6nyn",
        "hZm-fFLRyTRO"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "* In this assignment you will be building the **Encoder** part of the Transformer architecture.\n",
        "* You will be using the **PyTorch** framework to implement the following components\n",
        "  * Encoder Layer that contains\n",
        "    * Multi-Head Attention (MHA) Module\n",
        "    * Position-wise Feed Forward Neural Network\n",
        "\n",
        "  * Output layer that takes the encoder output and predicts the token_ids.\n",
        "\n",
        "  * Optionally, study whether adding positional information is helpful.\n",
        "  \n",
        "* **DO NOT** USE Built-in **TRANSFORMER LAYERS** as it affects the reproducibility.\n",
        "\n",
        "* You will be given with a configuration file that contains information on various hyperparameters such as embedding dimension, vocabulary size,number heads and so on\n",
        "\n",
        "* Use ReLU activation function and Stochastic Gradient Descent optimizer\n",
        "* Here are a list of helpful Pytorch functions (does not mean you have to use all of them) for this and subsequent assignments\n",
        "  * [torch.matmul](https://pytorch.org/docs/stable/generated/torch.matmul.html#torch-matmul)\n",
        "  * [torch.bmm](https://pytorch.org/docs/stable/generated/torch.bmm.html)\n",
        "  * torch.swapdims\n",
        "  * torch.unsqueeze\n",
        "  * torch.squeeze\n",
        "  * torch.argmax\n",
        "  * [torch.Tensor.view](https://pytorch.org/docs/stable/generated/torch.Tensor.view.html)\n",
        "  * [torch.nn.Embedding](https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html)\n",
        "  * [torch.nn.Parameter](https://pytorch.org/docs/stable/generated/torch.nn.parameter.Parameter.html)\n",
        "  * torch.nn.Linear\n",
        "  * torch.nn.LayerNorm\n",
        "  * torch.nn.ModuleList\n",
        "  * torch.nn.Sequential\n",
        "  * [torch.nn.CrossEntropyLoss](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html)\n",
        "  \n",
        "* Important: **Do not** set any global seeds.\n",
        "\n",
        "* Helpful resources to get started with\n",
        "\n",
        " * [Annotated Transformers](https://nlp.seas.harvard.edu/annotated-transformer/)\n",
        " * [PyTorch Source code of Transformer Layer](https://pytorch.org/docs/stable/generated/torch.nn.Transformer.html)\n",
        "\n"
      ],
      "metadata": {
        "id": "3BzlkwtBUSLZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "xp0X3WMuWEYZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import Tensor\n",
        "\n",
        "import torch.nn as nn\n",
        "from torch.nn import Parameter\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.functional import one_hot\n",
        "\n",
        "import torch.optim as optim\n",
        "\n",
        "from  pprint import pprint\n",
        "from yaml import safe_load\n",
        "import requests\n",
        "from io import BytesIO\n",
        "import math\n",
        "from torch.nn.init import xavier_uniform_"
      ],
      "metadata": {
        "id": "OR-MhDgVWMYE"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Configuration"
      ],
      "metadata": {
        "id": "WbHXnQ2WWlHO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#do not edit this cell\n",
        "config_url = \"https://raw.githubusercontent.com/Arunprakash-A/LLM-from-scratch-PyTorch/main/config_files/enc_config.yml\"\n",
        "response = requests.get(config_url)\n",
        "config = response.content.decode(\"utf-8\")\n",
        "config = safe_load(config)\n",
        "pprint(config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0GaFbEI1WnBD",
        "outputId": "d5c6fe16-88d0-4a41-99b2-0f90e40991e4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input': {'batch_size': 10, 'embed_dim': 32, 'seq_len': 8, 'vocab_size': 10},\n",
            " 'model': {'d_ff': 128,\n",
            "           'd_model': 32,\n",
            "           'dk': 4,\n",
            "           'dq': 4,\n",
            "           'dv': 4,\n",
            "           'n_heads': 8,\n",
            "           'n_layers': 6}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#do not edit this cell\n",
        "vocab_size = config['input']['vocab_size']\n",
        "batch_size = config['input']['batch_size']\n",
        "seq_len = config['input']['seq_len']\n",
        "embed_dim = config['input']['embed_dim']"
      ],
      "metadata": {
        "id": "G5I_iBP7XZod"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Here, you are directly given with the token ids\n",
        "* Assume that length of all sequences are equal to the context length (T) (so that we do not need to bother about padding shorter sequences while batching)"
      ],
      "metadata": {
        "id": "iHswIewIX5aE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# do not edit this cell\n",
        "data_url = 'https://github.com/Arunprakash-A/LLM-from-scratch-PyTorch/raw/main/config_files/w1_input_tokens'\n",
        "r = requests.get(data_url)\n",
        "token_ids = torch.load(BytesIO(r.content))\n",
        "print(token_ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jaawBcu3a3jX",
        "outputId": "8f3d6a99-ce02-4804-d2bb-f3d304d90098"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[5, 7, 5, 6, 3, 8, 7, 5],\n",
            "        [7, 2, 7, 1, 2, 1, 1, 7],\n",
            "        [1, 0, 0, 3, 6, 3, 0, 8],\n",
            "        [5, 0, 2, 8, 6, 5, 5, 3],\n",
            "        [3, 5, 4, 8, 5, 0, 7, 3],\n",
            "        [8, 6, 7, 4, 4, 4, 0, 1],\n",
            "        [5, 8, 1, 0, 1, 1, 0, 3],\n",
            "        [1, 7, 8, 8, 0, 5, 3, 7],\n",
            "        [7, 7, 1, 4, 5, 6, 7, 0],\n",
            "        [1, 7, 2, 8, 3, 0, 0, 4]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building the sub-layers"
      ],
      "metadata": {
        "id": "ZhMRsvQvZh6v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# do not edit this cell\n",
        "dq = torch.tensor(config['model']['dq'])\n",
        "dk = torch.tensor(config['model']['dk'])\n",
        "dv = torch.tensor(config['model']['dv'])\n",
        "dmodel = embed_dim\n",
        "heads = torch.tensor(config['model']['n_heads'])\n",
        "d_ff = config['model']['d_ff']"
      ],
      "metadata": {
        "id": "29nA7XtsZn4t"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Multi-Head Attention\n",
        "\n",
        " * Be mindful when using `torch.matmul`\n",
        " * Ensure that you understood what is being computed (because matrix product is not commutative)\n",
        " * Randomly initialize the parameters using normal distribution with the following seed values\n",
        "  * $W_Q:$(seed=43)\n",
        "  * $W_K:$(seed=44)\n",
        "  * $W_V:$(seed=45)\n",
        "  * $W_O:$(seed=46)"
      ],
      "metadata": {
        "id": "vxyfd2nfZ3on"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MHA(nn.Module):\n",
        "\n",
        "    def __init__(self, dmodel, dq, dk, dv, heads):\n",
        "        super(MHA, self).__init__()\n",
        "        self.heads = heads\n",
        "        self.dq = dq\n",
        "        self.dk = dk\n",
        "        self.dv = dv\n",
        "        self.dmodel = dmodel\n",
        "        self.dropout = nn.Dropout(p = 0.1)\n",
        "\n",
        "        self.WQ = nn.Parameter(self.init_param(dmodel, heads * dq, seed = 43))\n",
        "        self.WK = nn.Parameter(self.init_param(dmodel, heads * dk, seed = 44))\n",
        "        self.WV = nn.Parameter(self.init_param(dmodel, heads * dv, seed = 45))\n",
        "        self.WO = nn.Parameter(self.init_param(heads * dv, dmodel, seed = 46))\n",
        "\n",
        "        self.scaling_factor = math.sqrt(dk)\n",
        "\n",
        "    def init_param(self, *size, seed):\n",
        "        torch.manual_seed(seed)\n",
        "        return torch.randn(size)\n",
        "\n",
        "    def forward(self, H = None):\n",
        "        '''\n",
        "        Input  : Size  [BS, T, dmodel]\n",
        "        Output : Size  [BS, T, dmodel]\n",
        "        '''\n",
        "        BS, T, _ = H.shape\n",
        "\n",
        "        Q = torch.matmul(H, self.WQ.T)\n",
        "        K = torch.matmul(H, self.WK.T)\n",
        "        V = torch.matmul(H, self.WV.T)\n",
        "\n",
        "        Q = Q.view(BS, T, self.heads, self.dq).transpose(1, 2)\n",
        "        K = K.view(BS, T, self.heads, self.dk).transpose(1, 2)\n",
        "        V = V.view(BS, T, self.heads, self.dv).transpose(1, 2)\n",
        "\n",
        "        attention_scores = torch.matmul(Q, K.transpose(-2, -1)) / self.scaling_factor\n",
        "        attention = F.softmax(attention_scores, dim = -1)\n",
        "        # attention = self.dropout(attention)\n",
        "\n",
        "        out = torch.matmul(attention, V)\n",
        "        out = out.transpose(1, 2).contiguous().view(BS, T, -1)\n",
        "        out = torch.matmul(out, self.WO.T)\n",
        "        return out"
      ],
      "metadata": {
        "id": "GEihgqiTZ0E_"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pointwise FFN\n",
        "\n",
        "* Randomly initialize the parameters using normal distribution with the following seed values\n",
        "  * $W_{1}:$(seed=47)\n",
        "  * $W_2:$(seed=48)  "
      ],
      "metadata": {
        "id": "B7XgQNSRwO0J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FFN(nn.Module):\n",
        "\n",
        "    def __init__(self, dmodel, d_ff):\n",
        "        super(FFN, self).__init__()\n",
        "        torch.manual_seed(47)\n",
        "        self.linear1 = nn.Linear(dmodel, d_ff)\n",
        "        self.dropout = nn.Dropout(p = 0.1)\n",
        "        torch.manual_seed(48)\n",
        "        self.linear2 = nn.Linear(d_ff, dmodel)\n",
        "        self._reset_parameters()\n",
        "\n",
        "    def _reset_parameters(self):\n",
        "        nn.init.kaiming_normal_(self.linear1.weight, mode = 'fan_out', nonlinearity = 'relu')\n",
        "        nn.init.zeros_(self.linear1.bias)\n",
        "        nn.init.kaiming_normal_(self.linear2.weight, mode = 'fan_out', nonlinearity = 'relu')\n",
        "        nn.init.zeros_(self.linear2.bias)\n",
        "\n",
        "    def forward(self, x):\n",
        "        '''\n",
        "        Input  : Size [BS, T, dmodel]\n",
        "        Output : Size [BS, T, dmodel]\n",
        "        '''\n",
        "        x = self.linear1(x)\n",
        "        x = F.relu(x)\n",
        "        # x = self.dropout(x)\n",
        "        out = self.linear2(x)\n",
        "        return out"
      ],
      "metadata": {
        "id": "InQxHsqUv9b6"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Output Layer\n",
        "\n",
        "* Randomly initialize the linear layer\n",
        " * $W_L:$(seed=49)\n"
      ],
      "metadata": {
        "id": "Y2-ALRSRwVxC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class OutputLayer(nn.Module):\n",
        "\n",
        "    def __init__(self, dmodel, vocab_size):\n",
        "        super(OutputLayer, self).__init__()\n",
        "        torch.manual_seed(49)\n",
        "        self.linear = nn.Linear(dmodel, vocab_size)\n",
        "        self.dropout = nn.Dropout(p = 0.1)\n",
        "        self._reset_parameters()\n",
        "\n",
        "    def _reset_parameters(self):\n",
        "        nn.init.normal_(self.linear.weight, std = 0.02)\n",
        "        nn.init.zeros_(self.linear.bias)\n",
        "\n",
        "    def forward(self, representations):\n",
        "        '''\n",
        "        Input  :  Size  [BS, T, dmodel]\n",
        "        Output :  Size  [BS, T, vocab_size]\n",
        "        Note   : Do not apply the softmax. Just return the output of linear transformation\n",
        "        '''\n",
        "        out = self.linear(representations)\n",
        "        # out = self.dropout(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "25yaAbKHwXNb"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encoder Layer"
      ],
      "metadata": {
        "id": "7bD8YU5Ww2eF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderLayer(nn.Module):\n",
        "\n",
        "    def __init__(self, dmodel, dq, dk, dv, d_ff, heads):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "        self.mha = MHA(dmodel, dq, dk, dv, heads)\n",
        "        self.layer_norm_mha = nn.LayerNorm(dmodel)\n",
        "        self.ffn = FFN(dmodel, d_ff)\n",
        "        self.layer_norm_ffn = nn.LayerNorm(dmodel)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Pre Layer Norm\n",
        "        x_norm = self.layer_norm_mha(x)\n",
        "        attention_output = self.mha(x_norm)\n",
        "        x = x + attention_output\n",
        "\n",
        "        x_norm = self.layer_norm_ffn(x)\n",
        "        ffn_output = self.ffn(x_norm)\n",
        "        out = x + ffn_output\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "gCHDYAKWwz4r"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (Optional) Positional Encoding\n",
        "\n",
        " * We now use the positional embedding as defined in the [paper](https://arxiv.org/pdf/1706.03762v1.pdf) (differs a bit from the lecture).\n",
        " * Note that, the positional encoding for each position is fixed (not a learnable parameter)\n",
        " * However, we add this with the raw_embeddings which are learnable.\n",
        " * Therefore, it is important to create a class definition for PE and register PE parameters in the buffer (in case we move the model to GPU)\n",
        " * Just create a matrix of same size of input and add it to the embeddings"
      ],
      "metadata": {
        "id": "OZoWH79fdX_L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model, max_len = 500):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "\n",
        "        pe = pe.unsqueeze(0)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        x : Tensor, shape [batch_size, seq_len, embedding_dim]\n",
        "        Adjust the slicing of self.pe to match x's shape [batch_size, seq_len, embedding_dim]\n",
        "        \"\"\"\n",
        "        x = x + self.pe[:, :x.size(1)]\n",
        "        return x"
      ],
      "metadata": {
        "id": "pu6Zw_jpdSwp"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model with one encoder layer\n",
        "\n",
        " * The encoders' forward function accepts the token_ids as input\n",
        " * Generate the embeddings for the token ids by initializing the emebedding weights from normal distribution by setting the seed value to 50\n",
        " * Use `torch.nn.Embed()` to generate required embeddings"
      ],
      "metadata": {
        "id": "wrZ84eSyxYfE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, embed_dim, dq, dk, dv, d_ff, heads, num_layers = 1, max_len = 500):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.num_layers = num_layers\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
        "        torch.nn.init.xavier_uniform_(self.embedding.weight)\n",
        "        self.pos_encoder = PositionalEncoding(embed_dim, max_len)\n",
        "        self.encoder_layers = nn.ModuleList([EncoderLayer(embed_dim, dq, dk, dv, d_ff, heads) for _ in range(num_layers)])\n",
        "        self.final_layer_norm = nn.LayerNorm(embed_dim)\n",
        "        self.output_linear = nn.Linear(embed_dim, vocab_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        '''The input should be token ids of size [BS, T]'''\n",
        "        out = self.embedding(x) # Get the token embeddings\n",
        "        out = self.pos_encoder(out) # Add positional encodings\n",
        "        for layer in self.encoder_layers:\n",
        "            out = layer(out)\n",
        "        out = self.final_layer_norm(out)\n",
        "        logits = self.output_linear(out)\n",
        "        return logits"
      ],
      "metadata": {
        "id": "WctNu-Z-w5rd"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Encoder(vocab_size, dmodel, dq, dk, dv, d_ff, heads)\n",
        "print(\"Model : \\n\", model)\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr = 0.01)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "print(\"\\n Parameters : \\n\")\n",
        "for name, param in model.named_parameters():\n",
        "    print(name, param.size())"
      ],
      "metadata": {
        "id": "owqyMc_Fxghn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2bd0d326-867d-4b32-cf3d-29989dfb3021"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model : \n",
            " Encoder(\n",
            "  (embedding): Embedding(10, 32)\n",
            "  (pos_encoder): PositionalEncoding()\n",
            "  (encoder_layers): ModuleList(\n",
            "    (0): EncoderLayer(\n",
            "      (mha): MHA(\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (layer_norm_mha): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
            "      (ffn): FFN(\n",
            "        (linear1): Linear(in_features=32, out_features=128, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "        (linear2): Linear(in_features=128, out_features=32, bias=True)\n",
            "      )\n",
            "      (layer_norm_ffn): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
            "    )\n",
            "  )\n",
            "  (final_layer_norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
            "  (output_linear): Linear(in_features=32, out_features=10, bias=True)\n",
            ")\n",
            "\n",
            " Parameters : \n",
            "\n",
            "embedding.weight torch.Size([10, 32])\n",
            "encoder_layers.0.mha.WQ torch.Size([32, 32])\n",
            "encoder_layers.0.mha.WK torch.Size([32, 32])\n",
            "encoder_layers.0.mha.WV torch.Size([32, 32])\n",
            "encoder_layers.0.mha.WO torch.Size([32, 32])\n",
            "encoder_layers.0.layer_norm_mha.weight torch.Size([32])\n",
            "encoder_layers.0.layer_norm_mha.bias torch.Size([32])\n",
            "encoder_layers.0.ffn.linear1.weight torch.Size([128, 32])\n",
            "encoder_layers.0.ffn.linear1.bias torch.Size([128])\n",
            "encoder_layers.0.ffn.linear2.weight torch.Size([32, 128])\n",
            "encoder_layers.0.ffn.linear2.bias torch.Size([32])\n",
            "encoder_layers.0.layer_norm_ffn.weight torch.Size([32])\n",
            "encoder_layers.0.layer_norm_ffn.bias torch.Size([32])\n",
            "final_layer_norm.weight torch.Size([32])\n",
            "final_layer_norm.bias torch.Size([32])\n",
            "output_linear.weight torch.Size([10, 32])\n",
            "output_linear.bias torch.Size([10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training the model\n",
        "\n",
        " * Train the model for 30 epochs and compute the loss"
      ],
      "metadata": {
        "id": "Wmgf_oYl6hr0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(token_ids, epochs):\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        optimizer.zero_grad() # Zeroing the gradients at the start of the epoch\n",
        "        out = model(token_ids)\n",
        "        loss = criterion(out.view(-1, vocab_size), token_ids.view(-1))\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step() # Updating the weights after computing gradients\n",
        "\n",
        "        print(f'Epoch {epoch+1}, Loss: {loss.item()}')"
      ],
      "metadata": {
        "id": "Ebgg-hwGxxv4"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(token_ids, 30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HTqDJQA3k_gl",
        "outputId": "5341e209-50a6-4289-bc1d-020b7db26302"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 2.486140012741089\n",
            "Epoch 2, Loss: 2.469435214996338\n",
            "Epoch 3, Loss: 2.4535746574401855\n",
            "Epoch 4, Loss: 2.438473701477051\n",
            "Epoch 5, Loss: 2.424062967300415\n",
            "Epoch 6, Loss: 2.410287618637085\n",
            "Epoch 7, Loss: 2.3970999717712402\n",
            "Epoch 8, Loss: 2.3844549655914307\n",
            "Epoch 9, Loss: 2.372319459915161\n",
            "Epoch 10, Loss: 2.3606646060943604\n",
            "Epoch 11, Loss: 2.349456787109375\n",
            "Epoch 12, Loss: 2.338669538497925\n",
            "Epoch 13, Loss: 2.3282723426818848\n",
            "Epoch 14, Loss: 2.3182427883148193\n",
            "Epoch 15, Loss: 2.3085622787475586\n",
            "Epoch 16, Loss: 2.299208641052246\n",
            "Epoch 17, Loss: 2.2901668548583984\n",
            "Epoch 18, Loss: 2.2814218997955322\n",
            "Epoch 19, Loss: 2.2729623317718506\n",
            "Epoch 20, Loss: 2.2647767066955566\n",
            "Epoch 21, Loss: 2.2568514347076416\n",
            "Epoch 22, Loss: 2.2491748332977295\n",
            "Epoch 23, Loss: 2.2417359352111816\n",
            "Epoch 24, Loss: 2.234525203704834\n",
            "Epoch 25, Loss: 2.227534055709839\n",
            "Epoch 26, Loss: 2.220747947692871\n",
            "Epoch 27, Loss: 2.214155673980713\n",
            "Epoch 28, Loss: 2.2077486515045166\n",
            "Epoch 29, Loss: 2.2015154361724854\n",
            "Epoch 30, Loss: 2.195448398590088\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference"
      ],
      "metadata": {
        "id": "WE7gk3Wj6nyn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.inference_mode():\n",
        "  predictions =  model(token_ids)\n",
        "  # print(predictions)\n",
        "  predicted_token_ids = torch.argmax(predictions, dim = -1)"
      ],
      "metadata": {
        "id": "hYSG8_HCyGbm"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* See how many labels are correctly predicted"
      ],
      "metadata": {
        "id": "ORsnaC9L64U-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.count_nonzero(token_ids == predicted_token_ids))"
      ],
      "metadata": {
        "id": "w1EODJB3yJ1l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1adab007-2cd4-47e1-abd9-7772c53b7b67"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(15)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* The loss by now should be about 2.39 and the number of correct predictions should be about 37"
      ],
      "metadata": {
        "id": "4ifS0e81G2Hq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Encoder with N Layers\n",
        "\n",
        "  * The intialized parameters in all layers are identical\n",
        "  * use ModuleList to create **deep-copies** of encoder layer"
      ],
      "metadata": {
        "id": "hZm-fFLRyTRO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import copy"
      ],
      "metadata": {
        "id": "S2k-q-HJzASs"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "\n",
        "  def __init__(self, vocab_size, dmodel, dq, dk, dv, d_ff, heads, num_layers = 1):\n",
        "      super(Encoder, self).__init__()\n",
        "      self.embed = nn.Embedding(vocab_size, dmodel)\n",
        "      encoder_layer = EncoderLayer(dmodel, dq, dk, dv, d_ff, heads)\n",
        "      self.enc_layers = nn.ModuleList([copy.deepcopy(encoder_layer) for _ in range(num_layers)])\n",
        "      self.output_layer = OutputLayer(dmodel, vocab_size)\n",
        "\n",
        "  def forward(self,x):\n",
        "      '''\n",
        "      1. Get the embeddings\n",
        "      2. Pass it through encoder layer-1 and recursively pass the output to subsequent encoder layers\n",
        "      3. output the logits\n",
        "      '''\n",
        "      x = self.embed(x)\n",
        "      for layer in self.enc_layers:\n",
        "          x = layer(x)\n",
        "      out = self.output_layer(x)\n",
        "      return out"
      ],
      "metadata": {
        "id": "4c3LdS8AyU0K"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Train the stack of encoder layers with `num_layers=2` for the same 30 epochs"
      ],
      "metadata": {
        "id": "7E4xZxWi8XtV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Encoder(vocab_size, dmodel, dq, dk, dv, d_ff, heads, num_layers = 2)\n",
        "print(\"Model : \\n\", model)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr = 0.01)"
      ],
      "metadata": {
        "id": "ErrBXMf_zL5g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd62680b-41a0-4f4b-9c95-635ba7b806ec"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model : \n",
            " Encoder(\n",
            "  (embed): Embedding(10, 32)\n",
            "  (enc_layers): ModuleList(\n",
            "    (0-1): 2 x EncoderLayer(\n",
            "      (mha): MHA(\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (layer_norm_mha): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
            "      (ffn): FFN(\n",
            "        (linear1): Linear(in_features=32, out_features=128, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "        (linear2): Linear(in_features=128, out_features=32, bias=True)\n",
            "      )\n",
            "      (layer_norm_ffn): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
            "    )\n",
            "  )\n",
            "  (output_layer): OutputLayer(\n",
            "    (linear): Linear(in_features=32, out_features=10, bias=True)\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train(token_ids, epochs):\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        optimizer.zero_grad()\n",
        "        out = model(token_ids)\n",
        "        loss = criterion(out.view(-1, vocab_size), token_ids.view(-1))\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        print(f'Epoch {epoch+1}, Loss: {loss.item()}')"
      ],
      "metadata": {
        "id": "BeCyhBBmzY5d"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(token_ids, 30)"
      ],
      "metadata": {
        "id": "56s6UoRPzgMn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a57fe37-96eb-4d25-8a70-ad5eb0a56a2e"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 11.731537818908691\n",
            "Epoch 2, Loss: 10.939322471618652\n",
            "Epoch 3, Loss: 7.453770637512207\n",
            "Epoch 4, Loss: 5.148735046386719\n",
            "Epoch 5, Loss: 2.005950689315796\n",
            "Epoch 6, Loss: 0.7430357933044434\n",
            "Epoch 7, Loss: 0.06653666496276855\n",
            "Epoch 8, Loss: 0.0017537962412461638\n",
            "Epoch 9, Loss: 0.0012707902351394296\n",
            "Epoch 10, Loss: 0.001046122401021421\n",
            "Epoch 11, Loss: 0.0009081795578822494\n",
            "Epoch 12, Loss: 0.0008121303981170058\n",
            "Epoch 13, Loss: 0.0007400725153274834\n",
            "Epoch 14, Loss: 0.0006832275539636612\n",
            "Epoch 15, Loss: 0.0006367857567965984\n",
            "Epoch 16, Loss: 0.0005978124099783599\n",
            "Epoch 17, Loss: 0.0005644476041197777\n",
            "Epoch 18, Loss: 0.0005354405147954822\n",
            "Epoch 19, Loss: 0.0005098740803077817\n",
            "Epoch 20, Loss: 0.0004871223645750433\n",
            "Epoch 21, Loss: 0.0004666811728384346\n",
            "Epoch 22, Loss: 0.00044818539754487574\n",
            "Epoch 23, Loss: 0.0004313509853091091\n",
            "Epoch 24, Loss: 0.00041591739864088595\n",
            "Epoch 25, Loss: 0.00040172497392632067\n",
            "Epoch 26, Loss: 0.0003886107006110251\n",
            "Epoch 27, Loss: 0.0003764517023228109\n",
            "Epoch 28, Loss: 0.0003651235601864755\n",
            "Epoch 29, Loss: 0.00035454920725896955\n",
            "Epoch 30, Loss: 0.00034465306089259684\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.inference_mode():\n",
        "  predictions =  model(token_ids)\n",
        "  predicted_token_ids = torch.argmax(predictions, dim = -1)"
      ],
      "metadata": {
        "id": "lWl0YGbI0Dy3"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.count_nonzero(token_ids == predicted_token_ids))"
      ],
      "metadata": {
        "id": "llZyhTY20JOQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4dd87cbd-b569-46cd-b70a-664fefc41203"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(80)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Now, the loss value should be about 1.9 and the number of correct preditions is about 38"
      ],
      "metadata": {
        "id": "aZkfYjpnLwax"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Count Number of Parameters"
      ],
      "metadata": {
        "id": "YJHxAYffFlVK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for parameter in model.parameters():\n",
        "  total_num_parameters = sum(p.numel() for p in model.parameters())\n",
        "\n",
        "print(\"Total number of parameters in the model (including the embedding layer) :\", total_num_parameters)"
      ],
      "metadata": {
        "id": "7xrviY4PFoHu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b819088-5566-475f-cef8-63b309fb30d3"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of parameters in the model (including the embedding layer) : 25802\n"
          ]
        }
      ]
    }
  ]
}